{"cells":[{"cell_type":"markdown","metadata":{"id":"ajJwK0RDElbm"},"source":["# **train.ipynb**\n","\n","본 파일에서는, **전처리한 네이버 영화 리뷰 데이터셋을 활용하여 우리가 생성한 BertModel을 학습**시켜볼 것이다. 이후, **최종 성능(테스트 정확도)까지 출력**해볼 것이다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TZatCnHqF2Yp"},"source":["연습 문제를 시작하기에 앞서, import_ipynb를 설치한 후 import 하여 train.ipynb에서 필요한 preproc.ipynb, model.ipynb 내 함수를 호출한다.  \n","또한, 필요한 라이브러리를 호출한다."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nTqcsIWyfqLQ"},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'preproc' from 'Preproc' (Preproc.ipynb)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimport_ipynb\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPreproc\u001b[39;00m \u001b[39mimport\u001b[39;00m preproc\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model, get_model_with_params, BertModelInitialization\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'preproc' from 'Preproc' (Preproc.ipynb)"]}],"source":["import import_ipynb\n","\n","from Preproc import preproc\n","from model import get_model, get_model_with_params, BertModelInitialization\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","from tqdm.notebook import tqdm\n","import time"]},{"cell_type":"markdown","metadata":{"id":"SDlQBib_GJzO"},"source":["모델의 예측 정확도를 산출하는 함수인 **accuracy**를 정의하자. 해당 함수는 학습한 모델의 validation 점수와 test의 결과를 계산할 때 사용된다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6AVv6tp-toc"},"outputs":[],"source":["# 정확도 계산 함수\n","def accuracy(preds, labels):\n","    f_pred = np.argmax(preds, axis=1).flatten()\n","    f_labels = labels.flatten()\n","    return np.sum(f_pred == f_labels) / len(f_labels)"]},{"cell_type":"markdown","metadata":{"id":"aOCbc_6vwBC_"},"source":["**잠깐 ✔ 랜덤시드 고정이란 무엇인가?**\n","> 학습된 모델의 결과를 동일하게 재현(Reproduction)하는 것은 여러가지 상황에서 팔요하다.  \n","> 모델을 돌릴 때마다 결과가 달라지지 않도록 고정하는 것이다.  \n","\n","- 수상자가 되어 코드의 정합성을 검증 받게 될 경우,\n","\n","- 경진대회 참가 도중 팀을 이루어 결과를 공유해야 되는 경우,\n","\n","- 논문을 작성하여 그 결과를 Reproduction 해야하는 경우 등 여러 상황에서 필요하다.  \n","\n","- 본 과제 역시, (1) preproc.ipynb 내 섹터 별 자동 점수 반환 및 (2) 최종 평가 과정에서 혼동을 방지하기 위하여 랜덤시드를 고정해야 한다. 주어진 2022 시드 값을 절대 수정하지 않도록 하자.\n","\n","참고 자료:\n","https://dacon.io/codeshare/2363\n","https://pytorch.org/docs/stable/notes/randomness.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLt4Ics9mbxh"},"outputs":[],"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 2022"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkWP2-37-4D3"},"outputs":[],"source":["# 랜덤하게 데이터를 추출하기 위한 seed 값 설정\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"markdown","metadata":{"id":"E6s9pw_8HVPV"},"source":["학습에 활용될 데이터셋 및 토크나이저를 지정하자. 이후, 데이터셋을 전처리하여 train, validation, test 각각의 데이터로더에 입력하자.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Dmau6rcf-2M"},"outputs":[],"source":["from tokenization import KoBertTokenizer\n","\n","# 전체 데이터를 불러오자.\n","whole_dataset = pd.read_csv('ratings.txt', delimiter=\"\\t\")\n","\n","# KoBERTTokenizer를 불러오자.\n","tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\")\n","\n","train_dataloader, validation_dataloader, test_dataloader = preproc(tokenizer, whole_dataset)"]},{"cell_type":"markdown","metadata":{"id":"tGUIlgWuHeEL"},"source":["BertModel을 생성하여 GPU 혹은 CPU에 등록하자.\n","- 이때 BertModelInitialization()를 실행할 경우 기존 Device에 등록된 BertModel은 초기화되니, 한 번만 실행한 이후로는 사용하지 않도록 유의하여 사용해야 한다.\n","- 디바이스를 설정하자.\n","- 본격적인 학습에 앞서 train에 대한 model, 옵티마이저, 스케줄러, 에폭을 지정하고, 모델의 그래디언트를 초기화하자."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tprWhba8ksrA"},"outputs":[],"source":["# 기존 Device에 등록된 BertModel은 초기화되니, 유의하여 사용할 것.\n","# 한 번만 실행하고, 그 이후로는 사용하지 않도록 조심!\n","BertModelInitialization()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfzwRm9ukQ7D"},"outputs":[],"source":["# GPU 디바이스 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model, optimizer, scheduler, epochs = get_model_with_params(len(train_dataloader), device)\n","\n","# 그래디언트 초기화\n","model.zero_grad()"]},{"cell_type":"markdown","metadata":{"id":"Ja_iVrSEILy9"},"source":["**train 및 validation**  \n","본격적으로 학습을 진행해보자. epoch 만큼 학습 loop를 반복할 것이다.\n","- 우리가 생성한 model에, 배치 데이터에 대한 input_ids, attention_mask, labels 변수를 입력하여 순전파를 진행할 것이다.\n","- 이후 역전파 과정을 통해 매개변수가 조절되며 학습이 이루어진다.\n","- 한 차례 학습이 이루어질 때마다 average training loss 및 validation 정확도를 출력할 것이다.\n","- 학습이 완료된 모델을 특정 경로(PATH)에 저장할 것이다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Vpjdar0-1U_"},"outputs":[],"source":["# 에폭만큼 반복\n","for epoch_i in range(epochs):\n","    print(\"\")\n","    print('========{:}번째 Epoch / 전체 {:}회 ========'.format(epoch_i + 1, epochs))\n","    print('훈련 중')\n","\n","    total_loss = 0 # 로스 초기화\n","    sum_loss = 0\n","    model.train()  # 훈련모드로 변경\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","\n","        if step % 50 == 0:\n","          print(\"{}번째 까지의 평균 loss : {}\".format(step, sum_loss/50))\n","          sum_loss = 0\n","\n","        batch = tuple(t.to(device) for t in batch)   # 배치를 GPU에 넣음\n","        b_input_ids, b_input_mask, b_labels = batch  # 배치에서 데이터 추출\n","\n","        # model.ipynb에서 model 함수를 정의할 때 BertForSequenceClassification를 활용하였다.\n","        # 여기서 BertForSequenceClassification는 input_ids, attention_mask, labels 변수를 입력받는 'forward' 함수를 내장한다.\n","        # forward 함수는 forward(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states)와 같은 함수 파라미터를 갖는다.\n","        # model 함수를 통해 forward를 수행하기 위해 우리가 입력해야 하는 변수는 input_ids, attention_mask, labels 이다.\n","        # 위의 코드에서 정의한 배치 데이터를 model 함수에 입력하여, 배치에 대한 Forward를 수행해보자.\n","\n","        ##여기에 코드 작성\n","        outputs = ------------------------------------\n","\n","        loss = outputs[0]\n","        total_loss += loss.item() # 총 로스 계산\n","        sum_loss += loss.item()\n","\n","        loss.backward() # Backward 수행으로 그래디언트 계산\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # 그래디언트 클리핑\n","        optimizer.step() # 그래디언트를 통해 가중치 파라미터 업데이트\n","        scheduler.step()  # 스케줄러로 학습률 감소\n","        model.zero_grad() # 그래디언트 초기화\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","    #### 검증 ####\n","\n","    print(\"\")\n","    print(\"검증 중\")\n","\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_accuracy = 0\n","    nb_eval_steps = 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # 그래디언트 계산 안함\n","        with torch.no_grad():\n","            # Forward 수행\n","            outputs = ------------------------------------\n","\n","        # 결과 값 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","\n","# 학습된 모델을 해당 PATH에 저장\n","PATH = \"model.pt\"\n","torch.save(model.state_dict(), PATH)\n","\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"markdown","metadata":{"id":"hCWWsH4SJGW5"},"source":["**test**  \n","학습된 모델에 test용 데이터를 입력하여 test 결과를 출력하자.\n","- test용 데이터로더를 활용하여 배치 데이터에 대한 input_ids, mask를 model에 입력하여 순전파를 실행하고, 실행 결과를 outputs에 저장하자.\n","- 이때 test는 '학습'이 목적이 아니므로 그래디언트를 계산하지 않도록 한다.\n","- outputs와 실제 정답인 label_ids를 비교하여 모델의 최종 test accuracy를 확인하자. 모델이 88%의 정확도를 넘기는가?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dZC5xhuAut5"},"outputs":[],"source":["print(\"\")\n","print(\"테스트 중\")\n","\n","model.eval()\n","\n","# 변수 초기화\n","eval_accuracy = 0\n","nb_eval_steps = 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for batch in test_dataloader:\n","  # 배치를 GPU에 넣음\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  # 배치에서 데이터 추출\n","  b_input_ids, b_input_mask, b_labels = batch\n","\n","  # 그래디언트 계산 안함\n","  with torch.no_grad():\n","      # Forward 수행\n","      outputs = ------------------------------------\n","\n","  # 결과 값 구함\n","  logits = outputs[0]\n","\n","  # CPU로 데이터 이동\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  # 출력 로짓과 라벨을 비교하여 정확도 계산\n","  tmp_eval_accuracy = accuracy(logits, label_ids)\n","  eval_accuracy += tmp_eval_accuracy\n","  nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqj84FjuxpFw"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"cuda","language":"python","name":"cuda"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
